# Final Exam

A reminder that the final exam will be Sunday, March 11 at 11:30 am.
It will be in 008 Kemeny.

I have posted a [web page](../../exams/final-review.html) with
information and review questions.

# Parallel Computing

The algorithms and programs we have seen so far in this course all run
**serially**.  That is, they run on a computer with a single
processor, or **uniprocessor**, that executes one instruction at a
time:

![](uniprocessor.png)

For many years, most computers had this design&mdash;a uniprocessor
running one instruction at a time.

That is no longer true.  Most computers sold today&mdash;even laptop
systems&mdash;can run multiple instructions concurrently.  We have
various ways to design computers to run multiple instructions
concurrently, but we'll focus here on what has become the most
commonly found design: a single **multicore** chip that houses
multiple processing **cores**, each of which is a full-fledged
processor.  The individual processing cores on a multicore chip access
a common memory:

![](multicore.png)

Multicore computers can be harder to program than uniprocessors,
because we have to be careful about situations in which more than one
processor accesses a memory location.  For example, suppose processor
A writes 5 into variable `x` at the same time as processor B writes 7
into `x`.  What value does `x` end up getting?  In some cases, we
might see 5, and in other cases we might see 7.  You can imagine the
havoc that such behavior can cause.  We call this type of behavior
**nondeterministic**, because we cannot determine ahead of time with
certainty what will result.

So why do we have multicore computers at all?  Why not just keep
making uniprocessors faster?  After all, we've been doing just that
for decades now.  Indeed, processor speeds double approximately every
18 months.  (This statement is a variant on the famous **Moore's
Law**, which states that the number of transistors that we can
fabricate on a chip doubles approximately every two years.  The denser
we can pack transistors, the faster we can make the processor, because
when transistors are closer together, it takes less time for
electrical signals to travel between transistors.)

There are at least two reasons why we cannot rely on uniprocessors
continuing to get faster.  First, we will eventually hit fundamental
physical limits on how small we can make transistors and the tiny
wires on chips that connect transistors.  After all, once a transistor
gets down to the size of an atom, how much smaller can we go?  We
haven't hit these fundamental limits yet, but we're getting ever
closer.

The other reason is a limit that we have already hit.  The faster we
run a chip, the more energy it consumes and, in turn, the more heat it
has to dissipate.  When you use your laptop computer on your lap, you
feel the heat, don't you?  If a computer gets too hot, bad things
happen to it&mdash;bad things that require you to replace lots of
internal parts, if not the entire system.

With multicore computers, we can run as many instructions per second
as a faster uniprocessor.  Because each processing core runs slower,
however, a multicore computer can consume less energy, and we can
design it to keep away from the fundamental physical limits.  That's
why today, even laptop systems have two or four processing cores.
Predictions are that we'll see chips with 64 or more cores within the
next few years.

Thus, the sequential programs that most programmers have been writing
for years, if not decades, will fail to take advantage of the full
power of today's and tomorrow's processing chips.  It behooves us,
therefore, to understand something about how to write programs that
can take advantage of **parallel computers** with multiple processing
cores.

Before we go on to look at how to think about parallel programs, it is
worth noting that there are other ways to design parallel computers.
**Clusters** are built from individual computers&mdash;often simple
PC-class machines&mdash;connected by a dedicated network:

![](uni-cluster.png)

A typical cluster costs much more than an individual PC-class
computer, but it provides faster aggregate performance.  Programming a
cluster is different from programming a multicore computer, because
the memory is not shared among the processors; it's **distributed**
among the **nodes** of the cluster.  Each node contains one or more
processing cores, some memory, and often one or more disk drives.
Each node can directly access only its own memory and disk.  To get
information from one node to another, clusters typically send
**messages** over the dedicated network.

Now that multicore computers are common, we see clusters in which each
node has more than one core:

![](multi-cluster.png)

The highest-priced computers are **supercomputers**, which often use a
combination of custom processor designs and custom networks to deliver
the highest performance, in terms of instructions executed per second.
Supercomputers can cost millions of dollars.

## Parallel programming

Let's focus on a multicore computer with a shared memory, which is the
simplest to program.  Computer scientists have developed several ways
to program multicore machines.  Unfortunately, I don't know of any
that work well with Python and are easy to install on both Mac OS X
and Windows.  So we will be constrained to *thinking* about parallel
algorithms, rather than *running* them.  We'll still be able to
analyze our parallel algorithms, even though we won't run them.

We'll imagine that we have at our disposal $p$ processors, each of
which can access a common, shared memory.  In other words, any
processor can access any variable, any object, any item of any list,
etc.  To avoid the havoc that we hinted at above&mdash;when multiple
processors try concurrently to change the value of the same
variable&mdash;we will consider only programs in which that does not
occur.  In particular, we will partition our data among the $p$
processors, so that for an $n$-item list, each processor is
responsible for $n/p$ items.

From a programming point of view, we will call a for-loop that runs
for at most $p$ iterations, in which the result of each iteration has
no effect on other iterations, **parallelizable**.  We can imagine
each of the at most $p$ iterations running on its own processor **in
parallel** (i.e., concurrently), so that if each iteration takes time
$t$, all the iterations together take time only $O(t)$, rather than
the $O(pt)$ time they would take if we ran them serially.  For
example, if each iteration of a parallelizable for-loop takes constant
time, then the for-loop takes constant time when run in parallel.  On
the other hand, if we have $n$ items altogether and $n > p$, then each
iteration of a parallelizable for-loop has to work on $n/p$ items per
processor, so that the best we could hope for from the parallelizable
for-loop would be $O(n/p)$ time.

Let's make this idea more concrete.  Suppose we have three lists, `a`,
`b`, and `c`, each of length $p$, and we want to add the corresponding
items of `a` and `b` into the corresponding item of `c`.  Here's a
simple for-loop that does the job:

~~~{.python}
for i in range(p):
    c[i] = a[i] + b[i]
~~~

This for-loop is parallelizable, since each iteration has no effect on
other iterations.  Thus, because each iteration takes constant time,
if we have $p$ processors, then this for-loop runs in constant time,
i.e., $O(1)$ time, in parallel.

Now suppose that each of the lists `a`, `b`, and `c` has $n$ items,
where $n>p$.  To keep things simple, let's assume that $n$ is a
multiple of $p$, and let $m = n/p$; by our assumption, $m$ is an
integer.  Then here are nested for-loops that add the corresponding
items of `a` and `b` into the corresponding item of `c`:

~~~{.python}
# This outer for-loop is parallelizable.
for i in range(p):
    # This inner for-loop is not parallelizable.
    for j in range(m):
      c[i*m + j] = a[i*m + j] + b[i*m + j]
~~~

The idea here is that processor 0 is responsible for indices $0$ to
$m-1$, processor 1 is responsible for indices $m$ to $2m-1$, processor
2 is responsible for indices $2m$ to $3m-1$, and so on.  More
generally, processor $i$, for $i = 0, 1, 2, \ldots, p-1$, is
responsible for indices $im, im+1, im+2, \ldots, im+m-1$.  (Notice
that $im+m-1 = (i+1)m-1$.)  We can parallelize the outer for-loop, so
that each processor performs its $m = n/p$ iterations of the inner
for-loop in parallel with the other processors.  Since each iteration
of the inner for-loop takes constant time, this computation runs in
$O(n/p)$ time in parallel.

We'll see that we use another, familiar idea when we design parallel
algorithms: recursively halving the problem size.  If we have a
parallel algorithm for a problem of size $n$, where $n \leq p$, and
the algorithm uses parallelizable for-loops that take constant time
when run in parallel, but the algorithm also recurses on a subproblem
of size (approximately) $n/2$, then after $O(\log\: n)$ recursions, we
get down to a problem size of 1.  Such an algorithm runs in $O(\log\:
n)$ time in parallel, since each recursive call runs in constant time,
plus the time for the recursive calls it makes.

## Parallel reduction

A **reduction** operation applies an associative operator to the items
of a list, giving the single result of applying the operator.  For
example, a +-reduction on a list `a` with $n$ items gives the value
`a[0] + a[1] + a[2] + ... + a[n-2] + a[n-1]`.  (Recall that an
associative operator&mdash;let's call it $\oplus$ to keep it
generic&mdash;satisfies the property that $(x \oplus y) \oplus z = x
\oplus (y \oplus z)$ for any operands $x$, $y$, and $z$.)

At first glance, you might think that computing the +-reduction on a
list is inherently serial, because we have to first sum `a[0] + a[1]`,
and then add in `a[2]`, then add in `a[3]`, and so on.  But because
the operation we're performing&mdash;addition in this case&mdash;is
associative, we can add values in other orders.  For example, we could
first compute `a[0] + a[1] + a[2] + ... + a[n/2-1]`, and we could
compute `a[n/2] + a[n/2 + 1] + a[n/2 + 2] + ... + a[n-1]`, and we
could then sum these two results to give the +-reduction of the entire
list.  In other words, instead of parenthesizing our additions as
`((...((a[0] + a[1]) + a[2]) + ... + a[n-2]) + a[n-1])`, we could
parenthesize them as `(a[0] + a[1] + a[2] + ... + a[n/2-1]) + (a[n/2]
+ a[n/2 + 1] + a[n/2 + 2] + ... + a[n-1])`, where we can further
parenthesize the sums `(a[0] + a[1] + a[2] + ... + a[n/2-1])` and
`(a[n/2] + a[n/2 + 1] + a[n/2 + 2] + ... + a[n-1])` however we choose.

The function `parallel_reduce` in [reduce.py](reduce.py) shows how we
can compute the +-reduction on a list `a` in parallel.

~~~{.python}
# Return the sum of all values in an n-item list a, using parallelizable
# for-loops and recursion.  Takes O(log n) time in parallel with p processors,
# assuming that n <= p.
def parallel_reduce(a):
    n = len(a)
    
    if n == 1:
        return a[0]     # base case: only one value
    else:
        # Create a new list, sums, of half the size, rounding up if n is odd.
        half = (n+1) / 2
        sums = [None] * half
        
        # Using a parallelizable for-loop, add pairs of values in a into sums.
        for i in range(half-1):
            sums[i] = a[2*i] + a[2*i+1]
            
        # Need special code to handle the last one or two values in a, in
        # case n is odd.
        if n % 2 == 0:
            sums[half-1] = a[2*half-2] + a[2*half-1]
        else:
            sums[half-1] = a[2*half-2]
            
        # Having created sums of pairs, return the +-reduction of the sums.
        # This recursive call is on a problem of half the size.
        return parallel_reduce(sums)
~~~

This function assumes that list `a` has $n$ items, where $n \leq p$.
Instead of breaking the problem down as in the previous paragraph, it
works as follows.  We create a new list, `sums`, of half the size.
That is, `sums` has size $n/2$, represented by the variable `half`,
except that we round up when $n$ is odd by computing `half = (n+1) /
2`.  We then sum consecutive pairs of values of `a` into `sums`, so
that `sums[0]` equals `a[0] + a[1]`, `sums[1]` equals `a[2] + a[3]`,
`sums[2]` equals `a[4] + a[5]`, and so on.  The function uses special
code to handle the case when $n$ is odd, in which case the last item
of `sums` gets just the last value of `a`.  Observe that the
+-reduction of `a` must equal the +-reduction of `sums`.  Hence, we
simply recurse on `sums`, passing `sums` to the recursive call of
`parallel_reduce`, and we return the result of the recursive call.
The base case is when the length of the list is 1, in which case we
just return the value of `a[0]`.

Pictorially, here's how a single step of the recursion works on a list
with the values 2, 3, 4, 2, 3, 6, 5, 2:

![](reduce-single.png)

And here's how the entire recursion unfolds:

![](reduce-full.png)

To analyze this function, we observe that the for-loop is
parallelizable.  Why?  The computation in each iteration&mdash;filling
in `sums[i]`&mdash;is independent of the computation in all other
iterations.  Since $n \leq p$ and we have $p$ processors, we can
execute this for-loop in constant time in parallel.  Thus, each
recursive call takes constant time in parallel, plus the time for the
recursive call.  The number of recursive calls is $O(\log\: n)$, since
we (approximately) halve $n$ in each call.  (Rounding up $n/2$ when
$n$ is odd doesn't affect the number of recursive calls in terms of
big-Oh notation.)  Thus, we can perform a reduction operation in
parallel in $O(\log\: n)$ time.

Now, what about when $n > p$?  The `parallel_reduce_many` function in
[reduce.py](reduce.py) handles this case.

~~~{.python}
# Return the sum of all values in an (m*p-1)-item list a, using parallelizable
# for-loops and a call to parallel_reduce.  Assumes that processor i works on
# a[i*m] through a[i*m + m-1].  Takes O(m + log p) time in parallel with p processors.
def parallel_reduce_many(a, p, m):
    # Create a list for summing the values in each processor.
    sums = [0] * p
    
    # Using a parallelizable outer for-loop, sum up the values in each processor's
    # portion of a.  With p processors, this loop takes O(m) time.
    for i in range(p):
        # This inner for-loop is not parallelizable.
        for j in range(m):
            sums[i] += a[i*m + j]
            
    # Now we have a list of p sums, so just return what the recursive parallel_reduce
    # function returns.  This call takes O(log p) time in parallel with p processors.
    return parallel_reduce(sums)
~~~

The parameter $m$ equals $n/p$.  The idea is to create a list `sums`
of length $p$ and have each processor sum its own portion of $n/p$
items into one position of `sums`.  Then we can call `parallel_reduce`
on `sums` to produce the reduction of the entire list.  The outer
for-loop is parallelizable, because processor $i$ stores into only
`sums[i]`, and it accesses its own sublist of the list `a`, namely
`a[im..im + m-1]`.  By the time we call `parallel_reduce` on the
`sums` list, `sums[i]` has the sum of all the items in the sublist
`a[im..im + m-1]`.  Because `sums` has $p$ items, it makes sense to
call `parallel_reduce`, and this call returns the sum of all the items
in list `a`.

Although the outer for-loop is parallelizable, the inner for-loop is
not.  But each processor can run $n/p$ iterations of the inner
for-loop in parallel with the other processors.  Hence, the time to
run the outer for-loop in parallel is $O(n/p)$.  As we know, the call
to `parallel_reduce` takes $O(\log\: p)$ time when run in parallel,
and so `parallel_reduce_many` takes parallel time $O(n/p + \log\: p)$.
When $n/p > \log_2\: p$, the $n/p$ term dominates the running time,
and we get the best parallel speedup possible.  When $\log_2\: p >
n/p$, then $n/p$ must be pretty small: raise 2 to both sides, getting
$p > 2^{n/p}$, so we're not too disappointed that the running time is
not $O(n/p)$; $O(\log\: p)$ is still darned good.

## Parallel scanning

A **scan** operation is somewhat like a reduction in that we wish to
apply an associative operator to all items in a list.  Unlike a
reduction, which produces one answer, a scan operation on an $n$-item
list `a[0..n-1]` produces $n$ answers.  In particular, if the result
of the scan operation is in the $n$-item list `result`, then
`result[i]` equals `a[0] + a[1] + a[2] + ... + a[i-2] + a[i-1]`.  That
is, the $i$th position of the result should hold the sum of the first
$i-1$ items of `a`.  What about `result[0]`?  It should hold the
identity for the associative operator.  We'll focus on a +-scan, so
that `result[0]` should equal 0.

As an aside, we call this type of scan an **exclusive scan**, since
the value of `result[i]` does not include `a[i]`.  In an **inclusive
scan**, `result[i]` equals the sum of the first $i$ items (not $i-1$)
of `a`.  We focus on the exclusive scan for two reasons.  First, if we
have the result of an exclusive scan, it's easy enough to add in
`a[i]` into each position $i$ to get the result of an inclusive scan.
We cannot necessarily go backwards, because not all associative
operators have an inverse for every operand.  (For example, matrix
multiplication is associative, but if $A$, $B$, and $C$ are matrices,
and $C$ equals the matrix product $A \: B$, we cannot necessarily
determine $B$ given $A$ and $C$, since $A$ might not be invertible or
even square.)  Second, exclusive scans have more practical
applications than inclusive scans.  We'll see a good application of
exclusive scan later.

Now, *this* operation looks inherently serial.  It would certainly be
easy enough to compute it serially:

~~~{.python}
result[0] = 0

for i in range(1, n):
    result[i] = result[i-1] + a[i-1]
~~~

Seeing this computation makes us think that we need to compute
`result[i-1]` before computing `result[i]`.  Therefore, we would think
that we have to compute `result[0]`, then `result[1]`, then
`result[2]`, and so on.  That's a serial computation, and it would
take $O(n)$ time.

Believe it or not, we can perform a scan operation in $O(\log\: n)$
time when $n \leq p$.  In other words, scanning is no harder than
reduction, even though scanning seems inherently sequential.

Let's take an example of a +-scan, where the list <code>a</code> has
the values 2, 3, 4, 2, 3, 6, 5, 2.  We expect the result to be 0, 2,
5, 9, 11, 14, 20, 25.  Here's a schematic drawing of the process:

![](scan.png)

The code is the `parallel_scan` function in [scan.py](scan.py):

~~~{.python}
# Return a list of n values, whose ith value is the sum of all values in
# the first i-1 items of a, and whose 0th value is 0 (the identity for addition).
# Uses parallelizable for-loops and recursion.
# Takes O(log n) time in parallel with p processors, assuming that n <= p.
def parallel_scan(a):
    # Create a list to hold the result of the scan.
    n = len(a)
    result = [None] * n
    
    if n == 1:
        result[0] = 0       # base case: only one value
    else:
        # Create a new list, sums, of half the size, rounding up if n is odd.
        half = (n+1) / 2
        sums = [None] * half
        
        # Using a parallelizable for-loop, add pairs of values in a into sums.
        for i in range(half-1):
            sums[i] = a[2*i] + a[2*i+1]
            
        # Need special code to handle the last one or two values in a, in
        # case n is odd.
        if n % 2 == 0:
            sums[half-1] = a[2*half-2] + a[2*half-1]
        else:
            sums[half-1] = a[2*half-2]
            
        # Having created sums of pairs, return the +-scan of the sums.
        # This recursive call is on a problem of half the size.
        recursive_result = parallel_scan(sums)
        
        # Now, for even values of i, recursive_result[i/2] holds the sum of
        # all values from a[0] through a[i-1], so that's what we want in result[i].
        # For odd values of i, recursive_result[i/2] holds the sum of all values
        # from a[0] through a[i-2], so result[i] should get the sum of
        # recursive_result[i/2] and a[i-1].
        # This for-loop is parallelizable.
        for i in range(n):
            if i % 2 == 0:
                result[i] = recursive_result[i/2]
            else:
                result[i] = recursive_result[i/2] + a[i-1]
                
    return result
~~~

We first sum pairs of consecutive pairs of values of `a` into a list
`sums`, exactly as we did in the recursive `parallel_reduce` function.
As in `parallel_reduce`, the list `sums` has $n/2$ items, rounding up
if $n$ is odd.  In our example, `sums` has the values 5, 6, 9, 7.  As
in `parallel_reduce`, we recurse on `sums`, but now we call
`parallel_scan` recursively, not `parallel_reduce`.  The recursive
call is on a problem half the size.  We assign the result to a list
named `recursive_result`.  In our example, `recursive_result` has the
values 0, 5, 11, 20.

Let's think about the situation after we return from the recursive
call.  For even indices $i$, `recursive_result[i/2]` holds the sum of
all values in `a[0]` through `a[i-1]`, and that's exactly what we want
in the $i$th position of the result.  Having created a list `result`
of length $n$, we simply set `result[i] = recursive_result[i/2]` for
even values of $i$.  For odd values of $i$, `recursive_result[i/2]`
holds the sum of all values in `a[0]` through `a[i-2]`, and so adding
in `a[i-1]` to `recursive_result[i/2]` gives us what we want in
`result[i]`.  We can think of filling in the `result` list as
interleaving and adding, where we take the values in
`recursive_result` and copy them into the even-indexed positions of
`result`, and we add the values of `recursive_result` to odd-indexed
values of `a`, putting the sums into the odd-indexed positions of
`result`.

When you look at the code in `parallel_scan`, you see that both the
for-loops are parallelizable.  Therefore, the analysis is the same as
for the `parallel_reduce` function, and we get that the parallel
running time is just $O(\log\: n)$.  We've succeeded in parallelizing
the scan operation!

The `parallel_scan_many` function handles the case when $n > p$.

~~~{.python}
# Return a list of m*p values, whose ith value is the sum of all values in the
# first i-1 items of a, and whose 0th value is 0 (the identity for addition).
# Uses parallelizable for-loops and a call to parallel_scan.  Assumes that
# processor i works on a[i*m] through a[i*m + m-1].  Takes O(m + log p) time
# in parallel with p processors.
def parallel_scan_many(a, p, m):
    # Create a list to hold the result of the scan.
    n = m * p
    prefix = [0] * n
    
    # Using a parallelizable for-loop, perform a scan on the values in each
    # processor's portion of a, so that prefix[i*m + j] has the sum of the values
    # in a[i*m] through a[i*m + j-1] and prefix[i*m] has 0.  With p processors,
    # this loop takes O(m) time.
    for i in range(p):
        # This inner for-loop is not parallelizable.
        for j in range(1, m):
            prefix[i*m + j] = prefix[i*m + j-1] + a[i*m + j-1]
            
    # Create a list, prior_sums, where prior_sums[i] will hold the sum of all
    # the values in processor i's portion of a.
    prior_sums = [None] * p
    
    # Using a parallelizable for-loop, fill in prior_sums.
    for i in range(p):
        prior_sums[i] = prefix[i*m + m-1] + a[i*m + m-1]
        
    # Perform a scan on prior_sums, so that prior_sums[i] will hold the
    # sum of all values in portions of a belonging to processors 0 through i-1.
    # This call takes O(log p) time in parallel with p processors.
    prior_sums = parallel_scan(prior_sums)
    
    # Using a parallelizable outer for-loop, add in the prior sums to the
    # scan values already computed.
    for i in range(1, p):
        # This inner for-loop is not parallelizable.
        for j in range(m):
            prefix[i*m + j] += prior_sums[i]
            
    return prefix
~~~

As before, we denote $n/p$ by $m$.  We start by performing a scan on
the values in each processor's portion of the list `a`, placing the
results into the list `prefix`.  The `prefix` list will eventually
hold the result of the scan.  Processor $i$ is responsible for the
sublist from `a[i*m]` through `a[i*m + m-1]`, and so we want
`prefix[i*m + j]` to hold the sum `a[i*m] + a[i*m + 1] + a[i*m + 2] +
... + a[i*m + j-1]`, and `prefix[i*m]` should hold 0.  We perform this
scan using nested for-loops, where the outer loop is parallelizable
and the inner loop is not.  If we perform the outer loop in parallel,
then the parallel running time of these loops is $O(n/p)$.

We need to add into each item of `prefix` the sum of the values in all
previous processors.  In other words, we want to add into `prefix[i*m
+ j]`, where $0 \leq j < m$, the sum `a[0] + a[1] + a[2] + ... + a[i*m
- 1]`.  We create a list `prior-sums` of length $p$, where
`prior_sums[i]` will eventually have the sum of all the values
belonging to processors 0 through $i-1$.  Initially, `prior_sums[i]`
gets the sum of all of processor $i$'s values by assigning to it
`prefix[i*m + m-1] + a[i*m + m-1]` (recall that `prefix[i*m + m-1]`
has `a[i*m] + a[i*m + 1] + a[i*m + 2] + ... + a[i*m + m-2]`, so that
adding in `a[i*m + m-1]` gives the sum of all of processor $i$'s
portion of `a`).  We then call `parallel_scan` on `prior_sums`,
assigning the result back into `prior_sums`, so that `prior_sums[i]`
does hold the sum of all the values belonging to processors 0 through
$i-1$ We initialize `prior_sums` in a parallelizable for-loop, and of
course the call to `parallel_scan` takes $O(\log\: p)$ time.

Once we have `prior_sums` the way we want it, we just add
`prior_sums[i]` into each value in `prefix[i*m..i*m + m-1]`.  We do so
for processors $1, 2, \ldots, p$; we don't need to add anything into
processor 0's portion of `a`.  We perform this addition using nested
loops, with the outer loop being parallelizable and the inner loop not
parallelizable.  Once again, the parallel running time is
$O(n/p)$.

As in the `parallel_reduce_many` function, the total parallel running
time of `parallel_scan_many` function works out to $O(n/p + \log\:
p)$.

## Partitioning in parallel

Recall how quicksort relies on partitioning a list.  In fact, that's
really all that quicksort is: each recursive call partitions a sublist
of the full list.  We can parallelize quicksort by parallelizing
partitioning.  Scan operations are key, along with two other parallel
operations, meld and permute, which we'll see.

### Copy-scans

Earlier, I said that you can scan with any associative operator.  The
only examples we have seen so far use addition, performing a +-scan.
If we're a little bit creative, we can see how to couch other
operations as scans.  For example, suppose that we want to copy the
value in `a[0]` to each item in `a`.  We can use a scan for that!
How?  Let's define $@$ as a binary operator that just evaluates to its
left argument: $x \:@\: y = x$.  This operator is associative: $(x
\:@\: y) \:@\: z = x \:@\: z = x$ and $x \:@\: (y \:@\: z) = x \:@\: y
= x$.  Just as addition has the identity 0 ($0 + x = x$) and
multiplication has the identity 1 ($1 * x = x$), we'll make a special
symbol \$ for the identity for the $@$ operator: $\$ \:@\: x = x$ for
any value $x$.

In an exclusive +-scan, position 0 of the resulting list gets the
identity 0, so in an exclusive $@$-scan, position 0 of the resulting
list will get the identity \$.  Now we can see how a $@$-scan would
copy the value in `a[0]` to all positions of the resulting list,
except for position 0:

![](copy-scan.png)

After performing this operation, to get the value 2 into all positions
of the resulting list, we just need copy `a[0]` into the 0th position
of the resulting list.

### Meld operations

A **meld** operation takes values from $k$ lists, where $k \geq 2$,
and combines them into a single list, according to $k$ boolean lists.
This operation is best illustrated with an example.  Here, we meld $k
= 3$ lists&mdash;`x`, `y`, and `z`&mdash; holding values, according to
$k$ boolean lists&mdash;`a`, `b`, and `c`:

<pre>
       index  0  1  2  3  4  5  6  7  8  9 10 11 12 13

           a  0  0  <b>1</b>  <b>1</b>  <b>1</b>  0  0  <b>1</b>  0  0  <b>1</b>  <b>1</b>  <b>1</b>  <b>1</b>   
           x  0  0  <b>0</b>  <b>1</b>  <b>2</b>  3  3  <b>3</b>  4  4  <b>4</b>  <b>5</b>  <b>6</b>  <b>7</b>
       
           b  <b>1</b>  0  0  0  0  0  <b>1</b>  0  0  0  0  0  0  0
           y  <b>8</b>  9  9  9  9  9  <b>9</b> 10 10 10 10 10 10 10
       
           c  0  <b>1</b>  0  0  0  <b>1</b>  0  0  <b>1</b>  <b>1</b>  0  0  0  0
           z 10 <b>10</b> 11 11 11 <b>11</b> 12 12 <b>12</b> <b>13</b> 14 14 14 14
       
      result  8 10  0  1  2 11  9  3 12 13  4  5  6  7
</pre>

We indicate `True` by 1 and `False` by 0.  If `a[i]` has a 1, then the
$i$th position of the result gets `x[i]`; if `b[i]` has a 1, then the
$i$th position of the result gets `y[i]`; and if `c[i]` has a 1, then
the $i$th position of the result gets `z[i]`.  Values of `x`, `y`, and
`z` that go into the result are in boldface in the above example, as
are the boolean values that cause them to go there.  We assume that
for each position, exactly one of the boolean lists holds a 1 in that
position, as in the above example.
    
It's not hard to see how we can perform a meld operation in $O(k)$
time in parallel, assuming that $k \leq p$.

### Permute operations

A **permute** operation takes two lists, say `perm` and `x`, and it
produces an list, say `y`, such that `x[i]` equals `y[perm[i]]`.  We
assume that the `perm` list is a permutation (i.e., a rearrangement)
of the indices $0, 1, 2, ..., n-1$, so that what we are really doing
is permuting the values in the list `x` according to the indices in
`perm`.  For example, here's a permute operation that uses the result
of melding in the previous example as the `perm` list:

<pre>
        index  0  1  2  3  4  5  6  7  8  9 10 11 12 13
         perm  8 10  0  1  2 11  9  3 12 13  4  5  6  7
            x  4  6  2  1  3  7  4  2  5  6  1  2  1  3
            y  2  1  3  2  1  2  1  3  4  4  6  7  5  6
</pre>

Because each value in the `perm` list is unique and each processor can
store into the shared memory, a permute operation takes constant time
in parallel, assuming that $n \leq p$.

### Partitioning

Now we can see how to partition in parallel, assuming that $n \leq p$.
One difference from how we partitioned in the quicksort code we've
seen before is that we use the first item, not the last, as the pivot.
Another difference is that we'll make three partitions; in order from
left to right: items less than the pivot, items equal to the pivot,
and items greater than the pivot.  Quicksort would recurse on only the
left and right partitions, not the middle.  We'll show how to
partition by example, using the list `x` from the previous example.

1.  Copy-scan `x[0]` into a new list `pivot`, so that `pivot[i]`
equals `x[0]` for all $i$.
       
2. In parallel, compute three boolean lists: `less[i]` indicates
whether `x[i]` $<$ `pivot[i]`; `eq[i]` indicates whether `x[i]` equals
`pivot[i]`; and `greater[i]` indicates whether `x[i]` $>$ `pivot[i]`.

    For our example, here's what we have:
        <pre>
        index  0  1  2  3  4  5  6  7  8  9 10 11 12 13
            x  4  6  2  1  3  7  4  2  5  6  1  2  1  3
       
        pivot  4  4  4  4  4  4  4  4  4  4  4  4  4  4
       
         less  0  0  1  1  1  0  0  1  0  0  1  1  1  1
           eq  1  0  0  0  0  0  1  0  0  0  0  0  0  0
      greater  0  1  0  0  0  1  0  0  1  1  0  0  0  0
       </pre>

3. Perform a +-scan on each of `less`, `eq`, and `greater`, and
perform a +-reduction on `less` and `eq`.  Call the scan results
`less_scan`, `eq_scan`, and `greater_scan`.  Call the reduction
results `less_red` and `eq_red`.

    <pre>
           index  0  1  2  3  4  5  6  7  8  9 10 11 12 13
               x  4  6  2  1  3  7  4  2  5  6  1  2  1  3
       
           pivot  4  4  4  4  4  4  4  4  4  4  4  4  4  4
       
            less  0  0  1  1  1  0  0  1  0  0  1  1  1  1
              eq  1  0  0  0  0  0  1  0  0  0  0  0  0  0
         greater  0  1  0  0  0  1  0  0  1  1  0  0  0  0
       
       less_scan  0  0  0  1  2  3  3  3  4  4  4  5  6  7
         eq_scan  0  1  1  1  1  1  1  2  2  2  2  2  2  2
greater_scan  0  0  1  1  1  1  2  2  2  3  4  4  4  4
    </pre>


    `less_red` = 8 and `eq_red` = 2.

    At this point, if `x[i]` is less than `x[0]` (the pivot), then
`less_scan[i]` has the index of where we want to permute `x[i]`.  If
`x[i]` equals the pivot, then `eq_scan[i]` has the index of where we
want to permute `x[i]`, *but within the set of items equal to the
pivot*.  And if `x[i]` is greater than the pivot, then
`greater_scan[i]` has the index of where we want to permute `x[i]`,
*but within the set of items greater than the pivot*.
       
4. Copy-scan `less_red` and `eq_red`.  Add the result of copy-scanning
`less_red` into `eq_scan`, item by item, giving `eq_perm`.  Add the
sum of the results of copy-scanning `less_red` and `eq_red` into
`greater_scan`, item by item, giving `greater_perm`.
       
    <pre>
                 index  0  1  2  3  4  5  6  7  8  9 10 11 12 13
                     x  4  6  2  1  3  7  4  2  5  6  1  2  1  3
                 
                 pivot  4  4  4  4  4  4  4  4  4  4  4  4  4  4
                  
                  less  0  0  1  1  1  0  0  1  0  0  1  1  1  1
                    eq  1  0  0  0  0  0  1  0  0  0  0  0  0  0
               greater  0  1  0  0  0  1  0  0  1  1  0  0  0  0
             
             less_scan  0  0  0  1  2  3  3  3  4  4  4  5  6  7
               eq_scan  0  1  1  1  1  1  1  2  2  2  2  2  2  2
          greater_scan  0  0  1  1  1  1  2  2  2  3  4  4  4  4
    
    copy-scan less_red  8  8  8  8  8  8  8  8  8  8  8  8  8  8
      copy-scan eq_red  2  2  2  2  2  2  2  2  2  2  2  2  2  2
                   
	           eq_perm  8  9  9  9  9  9  9 10 10 10 10 10 10 10
	      greater_perm 10 10 11 11 11 11 12 12 12 13 14 14 14 14
    </pre>

    Now if `x[i]` equals the pivot, then `eq_perm[i]` has the index of
where we want to permute `x[i]` within the entire list, and if `x[i]`
is greater than the pivot, then `greater_scan[i]` has the index of
where we want to permute `x[i]` within the entire list.

5. Meld the lists `less_scan`, `eq_perm`, and `greater_perm`, using
the boolean lists `less`, `eq`, and `greater`.  Call the resulting
list `perm`, and it gives the index where each value of `x[i]` should
go.
       
    <pre>
                 index  0  1  2  3  4  5  6  7  8  9 10 11 12 13
                     x  4  6  2  1  3  7  4  2  5  6  1  2  1  3
                 
                 pivot  4  4  4  4  4  4  4  4  4  4  4  4  4  4
                  
                  less  0  0  1  1  1  0  0  1  0  0  1  1  1  1
                    eq  1  0  0  0  0  0  1  0  0  0  0  0  0  0
               greater  0  1  0  0  0  1  0  0  1  1  0  0  0  0
             
             less_scan  0  0  0  1  2  3  3  3  4  4  4  5  6  7
               eq_scan  0  1  1  1  1  1  1  2  2  2  2  2  2  2
          greater_scan  0  0  1  1  1  1  2  2  2  3  4  4  4  4
    
    copy-scan less_red  8  8  8  8  8  8  8  8  8  8  8  8  8  8
      copy-scan eq_red  2  2  2  2  2  2  2  2  2  2  2  2  2  2
                   
	           eq_perm  8  9  9  9  9  9  9 10 10 10 10 10 10 10
	      greater_perm 10 10 11 11 11 11 12 12 12 13 14 14 14 14
                  
                  perm  8 10  0  1  2 11  9  3 12 13  4  5  6  7
    </pre>

6. Permute the list `x` according to the indices in `perm`.  The
resulting list has the list `x` partitioned around the pivot `x[0]`.
       
    <pre>
                 index  0  1  2  3  4  5  6  7  8  9 10 11 12 13
                     x  4  6  2  1  3  7  4  2  5  6  1  2  1  3
                 
                 pivot  4  4  4  4  4  4  4  4  4  4  4  4  4  4
                  
                  less  0  0  1  1  1  0  0  1  0  0  1  1  1  1
                    eq  1  0  0  0  0  0  1  0  0  0  0  0  0  0
               greater  0  1  0  0  0  1  0  0  1  1  0  0  0  0
             
             less_scan  0  0  0  1  2  3  3  3  4  4  4  5  6  7
               eq_scan  0  1  1  1  1  1  1  2  2  2  2  2  2  2
          greater_scan  0  0  1  1  1  1  2  2  2  3  4  4  4  4
    
    copy-scan less_red  8  8  8  8  8  8  8  8  8  8  8  8  8  8
      copy-scan eq_red  2  2  2  2  2  2  2  2  2  2  2  2  2  2
                   
	           eq_perm  8  9  9  9  9  9  9 10 10 10 10 10 10 10
	      greater_perm 10 10 11 11 11 11 12 12 12 13 14 14 14 14
                  
                  perm  8 10  0  1  2 11  9  3 12 13  4  5  6  7
         
         partitioned x  2  1  3  2  1  2  1  3  4  4  6  7  5  6
    </pre>

    In this example, indices 0 through 7 of the partitioned list hold
values of `x` that are less than the pivot 4; indices 8 and 9 hold
values of `x` that equal the pivot 4; and indices 10 through 13 hold
values of `x` that are greater than the pivot 4.

Thus, we have successfully partitioned the list `x`.

Because $n \leq p$, each scan or reduce operation takes $O(\log\: n)$
time.  All other operations take constant time, and there are a
constant number of operations.  Therefore, we can partition in
$O(\log\: n)$ time in parallel.
