<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta name="generator" content="pandoc" />
  <title></title>
</head>
<body>
<!-- <script type="text/javascript" -->
<!--   src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"> -->
<!-- </script> -->
<script type="text/javascript"
 src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default">
</script>

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
});
</script>

<link rel="stylesheet" href="http://www.cs.dartmouth.edu/~cs1/azul.css" type="text/css" />


<div id = "menubar">
<ul>
<li><a href="http://www.cs.dartmouth.edu/~cs1/syllabus.html">Syllabus</a>
<li><a href="http://www.cs.dartmouth.edu/~cs1/schedule.html">Schedule</a>
<li><a href="http://www.cs.dartmouth.edu/~cs1/shortassign/short_assignments.html">Short assignments</a>
<li><a href="http://www.cs.dartmouth.edu/~cs1/labs/lab_assignments.html">Labs</a>
<li><a href="http://www.cs.dartmouth.edu/~cs1/exams.html">Exams</a>
<li><a href="http://www.cs.dartmouth.edu/~cs1/software.html">Course software</a>
<li> <a href="http://greenteapress.com/thinkpython/thinkpython.html">Book</a>
<li><A HREF="&#109;&#97;&#105;&#108;&#116;&#111;&#58;%63%73%31%68%65%6C%70%40%63%73%2E%64%61%72%74%6D%6F%75%74%68%2E%65%64%75">Get help</A>
</ul>
</div>

<div id = "termtitle"> CS 1:  Winter 2012 </div> 
<h1 id="np-completeness">NP-Completeness</h1>
<p>When I buy material products over the Internet, the seller has to get them delivered to my home. Most of the time, the seller uses a package-delivery company. I won't say which package-delivery company is most often used for the products I purchase, other than to say that brown trucks have been known to stop in front of my driveway every now and then.</p>
<h2 id="brown-trucks">Brown trucks</h2>
<p>The package-delivery company operates over 91,000 of these brown trucks in the U.S., as well as many others worldwide. Each of these trucks delivers parcels to several dozen residential and commercial addresses in each of at least five days per week. Every day, each truck starts and ends at a specific depot and drops off parcels at several dozen locations. The package-delivery company has a keen interest in minimizing the cost incurred by each truck as it makes several dozen stops each day. For example, one online source I consulted claimed that once the company mapped out routes for its drivers to reduce the number of left turns, it reduced the total distance traveled by its vehicles by 464,000 miles in an 18-month period, saving over 51,000 gallons of fuel, with the added benefit of decreasing carbon dioxide emissions by 506 metric tons.</p>
<p>How can the company minimize the cost of sending out each truck each day? Suppose that a given truck must deliver parcels to <span class="math"><em>n</em></span> locations on a particular day. Adding in the depot, there are <span class="math"><em>n</em> + 1</span> locations that the truck must visit. For each of these <span class="math"><em>n</em> + 1</span> locations, the company can calculate the costs of sending the truck to each of the other <span class="math"><em>n</em></span> locations, so that the company has an <span class="math">(<em>n</em> + 1) × (<em>n</em> + 1)</span> table of costs from location to location, where the entries on the diagonal are meaningless, since the <span class="math"><em>i</em></span>th row and the <span class="math"><em>i</em></span>th column correspond to the same location. The company wants to determine the route that starts and ends at the depot and visits all other <span class="math"><em>n</em></span> locations exactly once, such that the total cost of the entire route is as low as possible.</p>
<p>It is possible to write a computer program that will solve this problem. After all, if we consider a particular route and we know the order of stops on the route, then it's just a matter of looking up in table the costs of going from location to location and adding them up. Then we just have to enumerate all the possible routes and keep track of which one has the lowest total cost. The number of possible routes is finite, and so the program will terminate at some point and give the answer. That program doesn't seem so hard to write, does it?</p>
<p>Indeed, the program isn't hard to write.</p>
<p>It's hard to run.</p>
<p>The hitch is that the number of possible routes that visit <span class="math"><em>n</em></span> locations is enormous: <span class="math"><em>n</em>!</span> (<span class="math"><em>n</em></span>-factorial). Why? The truck starts at the depot. From there, any of the other <span class="math"><em>n</em></span> locations can be the first stop. From the first stop, any of the remaining <span class="math"><em>n</em> - 1</span> locations can be the second stop, and so there are <span class="math"><em>n</em> ⋅ (<em>n</em> - 1)</span> possible combinations for the first two stops, in order. Once we settle on the first two stops, any of <span class="math"><em>n</em> - 2</span> locations could be the third stop, giving <span class="math"><em>n</em> ⋅ (<em>n</em> - 1) ⋅ (<em>n</em> - 2)</span> possible orders for the first three stops. Extending this reasoning to the <span class="math"><em>n</em></span> delivery locations, the number of possible orders is <span class="math"><em>n</em> ⋅ (<em>n</em> - 1) ⋅ (<em>n</em> - 2)⋯3 ⋅ 2 ⋅ 1</span>, or <span class="math"><em>n</em>!</span>.</p>
<p>Recall that <span class="math"><em>n</em>!</span> grows faster than an exponential function; it's superexponential. Suppose that a truck delivers to <span class="math">20</span> addresses per day. (In the U.S., the company averages about <span class="math">170</span> packages per truck, so even allowing for multiple packages to be delivered to a single location, <span class="math">20</span> stops per day doesn't seem like an overestimate.) With <span class="math">20</span> stops, a computer program would have to enumerate <span class="math">20!</span> possible orders, and <span class="math">20!</span> equals 2,432,902,008,176,640,000. If the company's computers could enumerate and evaluate one trillion orders per second, it would require over <span class="math">28</span> days to try them all. And that's for just one day's worth of deliveries for one of over 91,000 trucks.</p>
<p>With this approach, if the company were to acquire and operate the computing power needed to find the lowest-cost routes for all trucks each day, the computing cost would easily wipe out the gains from the more efficient routes. No, this idea of enumerating all possible routes and keeping track of the best, although mathematically sound, is simply not practical. Is there a better way to find the lowest-cost route for each truck?</p>
<p>Nobody knows. (Or if somebody does know, he or she isn't telling.) Nobody has found a better way, yet nobody has proven that a better way cannot exist. How frustrating is that?</p>
<p>It's more frustrating than you might imagine. The problem of finding the lowest-cost routes for brown trucks is better known as the <strong>traveling-salesman problem</strong>, so-called because in its original formulation a traveling salesman has to visit <span class="math"><em>n</em></span> cities, starting and ending at the same city, and visit all the cities with the shortest possible tour. (Sorry about the gendered language. The name is historical, and if the problem were first being cast today, I hope that it would be known as the &quot;traveling-salesperson problem.&quot;) No algorithm that runs in time <span class="math"><em>O</em>(<em>n</em><sup><em>c</em></sup>)</span>, for any constant <span class="math"><em>c</em></span>, has ever been found for the traveling-salesman problem. We don't know of an algorithm that, given the intercity distances among <span class="math"><em>n</em></span> cities, finds the best possible order to visit the <span class="math"><em>n</em></span> cities in <span class="math"><em>O</em>(<em>n</em><sup>100</sup>)</span> time, <span class="math"><em>O</em>(<em>n</em><sup>1000</sup>)</span> time, or even <span class="math"><em>O</em>(<em>n</em><sup>1,000,000</sup>)</span> time.</p>
<p>It gets worse. Many problems—<em>thousands</em> of them—share this characteristic: for an input of size <span class="math"><em>n</em></span>, we know of no algorithm that runs in time <span class="math"><em>O</em>(<em>n</em><sup><em>c</em></sup>)</span> for any constant <span class="math"><em>c</em></span>, yet nobody has proven that no such algorithm could exist. These problems come from a wide variety of domains—logic, graphs, arithmetic, and scheduling among them.</p>
<p>To take the frustration to a whole new level, here's the most amazing fact:</p>
<blockquote>
<p>If there were an algorithm that ran in <span class="math"><em>O</em>(<em>n</em><sup><em>c</em></sup>)</span> time for <em>any</em> of these problems, where <span class="math"><em>c</em></span> is a constant, then there would be an algorithm that ran in <span class="math"><em>O</em>(<em>n</em><sup><em>c</em></sup>)</span> time for <em>all</em> of these problems.</p>
</blockquote>
<p>We call these problems <strong>NP-complete</strong>. An algorithm that runs in time <span class="math"><em>O</em>(<em>n</em><sup><em>c</em></sup>)</span> on an input of size <span class="math"><em>n</em></span>, where <span class="math"><em>c</em></span> is a constant, is a <strong>polynomial-time algorithm</strong>, so called because <span class="math"><em>n</em><sup><em>c</em></sup></span> with some coefficient would be the most significant term in the running time. We know of no polynomial-time algorithm for any NP-complete problem, but nobody has proven that it's impossible to solve some NP-complete problem in polynomial time.</p>
<p>And there's even more frustration: many NP-complete problems are almost the same as problems that we know how to solve in polynomial time. Just a small tweak separates them. For example, there's a well known algorithm that finds shortest paths from a single start vertex in a weighted, directed graph, even if the graph has negative-weight edges, in <span class="math"><em>O</em>(<em>n</em><em>m</em>)</span> time, where the graph has <span class="math"><em>n</em></span> vertices and <span class="math"><em>m</em></span> edges. If the graph is given as adjacency lists, then the input size is <span class="math"><em>O</em>(<em>n</em> + <em>m</em>)</span>. Let's assume that <span class="math"><em>m</em> ≥ <em>n</em></span>; then the input size is <span class="math"><em>O</em>(<em>m</em>)</span> and <span class="math"><em>n</em><em>m</em> ≤ <em>m</em><sup>2</sup></span>, and so the running time of the algorithm is polynomial in the input size. (You can get the same result if <span class="math"><em>n</em> &gt; <em>m</em></span>.) So finding <em>shortest</em> paths is easy. You might be surprised to learn, however, that finding a <em>longest</em> acyclic path (that is, a longest path without cycles) between two vertices is NP-complete. In fact, merely determining whether a graph contains a path without cycles with at least a given number of edges is NP-complete.</p>
<p>As another example of related problems, where one is easy and one is NP-complete, consider Euler tours and hamiltonian cycles. Both of these problems have to do with finding paths in an undirected graph, so that <span class="math">(<em>u</em>, <em>v</em>)</span> and <span class="math">(<em>v</em>, <em>u</em>)</span> are the same edge. An <strong>Euler tour</strong> (so named because the mathematician Leonhard Euler proved in 1736 that it was not possible to tour the city of Königsberg, Prussia by crossing every one of its seven bridges exactly once and ending up at the starting point) starts and ends at the same vertex and visits each <em>edge</em> exactly once, though it may visit each vertex more than once. A <strong>hamiltonian cycle</strong> (the name honors W. R. Hamilton, who in 1856 described a mathematical game on a graph known as the dodecahedron, in which one player sticks five pins in any five consecutive vertices and the other player must complete the path to form a cycle containing all the vertices) starts and ends at the same vertex and visits each <em>vertex</em> exactly once (except, of course, for the vertex at which it starts and ends). If we ask whether an undirected graph has an Euler tour, the algorithm is remarkably easy: determine the degree of each vertex. (Recall: the degree of a vertex is how many edges are incident on it.) The graph has an Euler tour if and only if the degree of every vertex is even. But if we ask whether an undirected graph has a hamiltonian cycle, that's NP-complete. Notice that the question is not &quot;what is the order of vertices on a hamiltonian cycle in this graph?&quot; but just the more basic &quot;yes or no: is it possible to construct a hamiltonian cycle on this graph?&quot;</p>
<p>NP-complete problems come up surprisingly often. If you are trying to find a polynomial-time algorithm for a problem that turns out to be NP-complete, you are likely to be in for a big helping of disappointment. The concept of NP-complete problems has been around since the early 1970s, and people were trying to solve problems that turned out to be NP-complete (such as the traveling-salesman problem) well before then. To date, we don't know whether a polynomial-time algorithm exists for any NP-complete problem, nor do we know that no such algorithm can exist. Many brilliant computer scientists have spent years on this question without resolving it.</p>
<h2 id="the-classes-p-and-np-and-np-completeness">The classes P and NP and NP-completeness</h2>
<p>So far in this course, we've been concerned about differences in running times such as <span class="math"><em>O</em>(<em>n</em><sup>2</sup>)</span> vs. <span class="math"><em>O</em>(<em>n</em> log <em>n</em>)</span>. When we talk about NP-completeness, however, we'll be happy if an algorithm runs in polynomial time, so that differences of <span class="math"><em>O</em>(<em>n</em><sup>2</sup>)</span> vs. <span class="math"><em>O</em>(<em>n</em> log <em>n</em>)</span> are insignificant. Computer scientists generally regard problems solvable by polynomial-time algorithms as &quot;tractable,&quot; meaning &quot;easy to deal with.&quot; If a polynomial-time algorithm exists for a problem, then we say that this problem is in the <strong>class P</strong>.</p>
<p>At this point, you might be wondering how could we possibly consider a problem that requires <span class="math"><em>O</em>(<em>n</em><sup>100</sup>)</span> time as tractable? For an input of size <span class="math"><em>n</em> = 10</span>, isn't <span class="math">10<sup>100</sup></span> a dauntingly large number? Yes, it is; in fact, the quantity <span class="math">10<sup>100</sup></span> is a googol (the origin of the name &quot;Google&quot;). Fortunately, we don't see algorithms that take <span class="math"><em>O</em>(<em>n</em><sup>100</sup>)</span> time. The problems in P that we encounter in practice require much less time. I've rarely seen polynomial-time algorithms that take worse than, say, <span class="math"><em>O</em>(<em>n</em><sup>5</sup>)</span> time. Moreover, once someone finds the first polynomial-time algorithm for a problem, others often follow with even more efficient algorithms. So if someone were to devise the first polynomial-time algorithm for a problem but it ran in time <span class="math"><em>O</em>(<em>n</em><sup>100</sup>)</span>, there would be a good chance that others would follow suit with faster algorithms.</p>
<p>Now suppose that you're given a proposed solution to a problem, and you want to verify that the solution is correct. For example, in the hamiltonian-cycle problem, a proposed solution would be a sequence of vertices. In order to verify that this solution is correct, you'd need to check that every vertex appears in the sequence exactly once, except that the first and last vertices should be the same, and if the sequence is <span class="math"><em>v</em><sub>1</sub>, <em>v</em><sub>2</sub>, <em>v</em><sub>3</sub>, …, <em>v</em><sub><em>n</em></sub>, <em>v</em><sub>1</sub></span> then the graph must contain edges <span class="math">(<em>v</em><sub>1</sub>, <em>v</em><sub>2</sub>), (<em>v</em><sub>2</sub>, <em>v</em><sub>3</sub>), (<em>v</em><sub>3</sub>, <em>v</em><sub>4</sub>), …, (<em>v</em><sub><em>n</em> - 1</sub>, <em>v</em><sub><em>n</em></sub>)</span> and back around to <span class="math">(<em>v</em><sub><em>n</em></sub>, <em>v</em><sub>1</sub>)</span>. You could easily verify that this solution is correct in polynomial time. If it is possible to verify a proposed solution to a problem in time polynomial in the size of the input to the problem, then we say that this problem is in the <strong>class NP</strong>. (You probably surmised that the name P comes from &quot;polynomial time.&quot; If you're wondering where the name NP comes from, it's from &quot;nondeterministic polynomial time.&quot; It's an equivalent, but not quite as intuitive, way of viewing this class of problems.) We call the proposed solution a <strong>certificate</strong>, and in order for the problem to be in NP, the certificate needs to be polynomial in the size of the input to the problem.</p>
<p>If you can solve a problem in polynomial time, then you can certainly verify a certificate for that problem in polynomial time. In other words, every problem in P is automatically in NP. The reverse—is every problem in NP also in P?—is the question that has perplexed computer scientists for all these years. We often call it the &quot;P = NP? problem.&quot;</p>
<p>The NP-complete problems are the &quot;hardest&quot; in NP. Informally, a problem is <strong>NP-complete</strong> if it satisfies two conditions: (1) it's in NP and (2) if a polynomial-time algorithm exists for the problem, then there is a way to convert <em>every</em> problem in NP into this problem in such a way as to solve them all in polynomial time. If a polynomial-time algorithm exists for <em>any</em> NP-complete problem—that is, if any NP-complete problem is in P—then P = NP. Because NP-complete problems are the hardest in NP, if it turns out that if any problem in NP is not polynomial-time solvable, then none of the NP-complete problems are. A problem is <strong>NP-hard</strong> if it satisfies the second condition for NP-completeness but may or may not be in NP.</p>
<h2 id="decision-problems-and-reductions">Decision problems and reductions</h2>
<p>So far, I've glossed over one important point about the problems that we're considering: they are all decision problems. In other words, their output is a single bit, indicating &quot;yes&quot; or &quot;no.&quot; I couched the Euler-tour and hamiltonian-cycle problems in this way: Does the graph have an Euler tour? Does it have a hamiltonian cycle?</p>
<p>What about the shortest-path problem? How can we pose the shortest-path problem as a yes/no problem? We can ask &quot;Does the graph contain a path between two specific vertices whose path weight is at most a given value <span class="math"><em>k</em></span>?&quot; We're not asking for the vertices or edges on the path, but just whether such a path exists. Assuming that path weights are integers, we can find the actual weight of the shortest path between the two vertices. How? Pose the question for <span class="math"><em>k</em> = 1</span>. If the answer is no, then try with <span class="math"><em>k</em> = 2</span>. If the answer is no, try with <span class="math"><em>k</em> = 4</span>. Keep doubling the value of <span class="math"><em>k</em></span> until the answer is yes. If that last value of <span class="math"><em>k</em></span> was <span class="math"><em>k</em>ʹ</span>, then the answer is somewhere between <span class="math"><em>k</em>ʹ / 2</span> and <span class="math"><em>k</em>ʹ</span>. Then find the true answer by using binary search with an initial interval of <span class="math"><em>k</em>ʹ / 2</span> to <span class="math"><em>k</em></span>.</p>
<p>The second condition for a problem to be NP-complete requires that if a polynomial-time algorithm exists for the problem, then there is a way to convert every problem in NP into this problem in such a way as to solve them all in polynomial time. Focusing on decision problems, let's see the general idea behind converting one decision problem, <span class="math"><em>X</em></span>, into another decision problem, <span class="math"><em>Y</em></span>, such that if there's a polynomial-time algorithm for <span class="math"><em>Y</em></span> then there's a polynomial-time algorithm for <span class="math"><em>X</em></span>. Here's the idea:</p>
<div class="figure">
<img src="reduction-overview.png" /><p class="caption"></p>
</div>
<p>We're given some input <span class="math"><em>x</em></span> of size <span class="math"><em>n</em></span> to problem <span class="math"><em>X</em></span>. We transform this input into an input <span class="math"><em>y</em></span> to problem <span class="math"><em>Y</em></span>, and we do so in time polynomial in <span class="math"><em>n</em></span>, say <span class="math"><em>O</em>(<em>n</em><sup><em>c</em></sup>)</span> for some constant <span class="math"><em>c</em></span>. The way we transform input <span class="math"><em>x</em></span> into input <span class="math"><em>y</em></span> has to obey an important property: if algorithm <span class="math"><em>Y</em></span> decides &quot;yes&quot; on input <span class="math"><em>y</em></span>, then algorithm <span class="math"><em>X</em></span> should decide &quot;yes&quot; on input <span class="math"><em>x</em></span>, and if <span class="math"><em>Y</em></span> decides &quot;no&quot; on <span class="math"><em>y</em></span>, then <span class="math"><em>X</em></span> should decide &quot;no&quot; on <span class="math"><em>x</em></span>. We call this transformation a <strong>polynomial-time reduction algorithm</strong>. Let's see how long the entire algorithm for problem <span class="math"><em>X</em></span> takes. The reduction algorithm takes <span class="math"><em>O</em>(<em>n</em><sup><em>c</em></sup>)</span> time, and its output cannot be longer than the time it took, and so the size of the reduction algorithm's output is <span class="math"><em>O</em>(<em>n</em><sup><em>c</em></sup>)</span>. But this output is the input <span class="math"><em>y</em></span> to the algorithm for problem <span class="math"><em>Y</em></span>. Since the algorithm for <span class="math"><em>Y</em></span> is a polynomial-time algorithm, on an input of size <span class="math"><em>m</em></span>, it runs in time <span class="math"><em>O</em>(<em>m</em><sup><em>d</em></sup>)</span> for some constant <span class="math"><em>d</em></span>. Here, <span class="math"><em>m</em></span> is <span class="math"><em>O</em>(<em>n</em><sup><em>c</em></sup>)</span>, and so the algorithm for <span class="math"><em>Y</em></span> takes time <span class="math"><em>O</em>((<em>n</em><sup><em>c</em></sup>)<sup><em>d</em></sup>)</span>, or <span class="math"><em>O</em>(<em>n</em><sup><em>c</em><em>d</em></sup>)</span>. Because both <span class="math"><em>c</em></span> and <span class="math"><em>d</em></span> are constants, so is <span class="math"><em>c</em><em>d</em></span>, and we see that the algorithm for <span class="math"><em>Y</em></span> is a polynomial-time algorithm. The total time for the algorithm for problem <span class="math"><em>X</em></span> is <span class="math"><em>O</em>(<em>n</em><sup><em>c</em></sup> + <em>n</em><sup><em>c</em><em>d</em></sup>)</span>, which makes it, too, a polynomial-time algorithm.</p>
<p>This approach shows that if problem <span class="math"><em>Y</em></span> is &quot;easy&quot; (solvable in polynomial time), then so is problem <span class="math"><em>X</em></span>. But we'll use polynomial-time reductions to show that problems are &quot;hard&quot;—in particular, NP-hard. And we'll use reductions to show the reverse: if problem <span class="math"><em>X</em></span> is NP-hard, then so is problem <span class="math"><em>Y</em></span>. Let's suppose that problem <span class="math"><em>X</em></span> is NP-hard and that there is a polynomial-time reduction algorithm to convert inputs to <span class="math"><em>X</em></span> into inputs to <span class="math"><em>Y</em></span>. Because <span class="math"><em>X</em></span> is NP-hard, there is a way to convert any problem, say <span class="math"><em>Z</em></span>, in NP into <span class="math"><em>X</em></span> such that if <span class="math"><em>X</em></span> has a polynomial-time algorithm, so does <span class="math"><em>Z</em></span>. Now you know how that conversion occurs, namely by a polynomial-time reduction:</p>
<div class="figure">
<img src="Z-to-X-reduction.png" /><p class="caption"></p>
</div>
<p>Because we can convert inputs to <span class="math"><em>X</em></span> into inputs to <span class="math"><em>Y</em></span> with a polynomial-time reduction, we can expand <span class="math"><em>X</em></span> as we did earlier:</p>
<div class="figure">
<img src="Z-to-X-to-Y-reduction.png" /><p class="caption"></p>
</div>
<p>Instead of grouping the polynomial-time reduction for <span class="math"><em>X</em></span> to <span class="math"><em>Y</em></span> and the algorithm for <span class="math"><em>Y</em></span> together, let's group the two polynomial-time reductions together:</p>
<div class="figure">
<img src="Z-to-Y-reduction-1.png" /><p class="caption"></p>
</div>
<p>Now we note that if we immediately follow the polynomial-time reduction for <span class="math"><em>Z</em></span> to <span class="math"><em>X</em></span> by the polynomial-time reduction from <span class="math"><em>X</em></span> to <span class="math"><em>Y</em></span>, we have a polynomial-time reduction from <span class="math"><em>Z</em></span> to <span class="math"><em>Y</em></span>:</p>
<div class="figure">
<img src="Z-to-Y-reduction-2.png" /><p class="caption"></p>
</div>
<p>Just to make sure that the two polynomial-time reductions in sequence together constitute a single polynomial-time reduction, we'll use a similar analysis to what we did before. Suppose that the input <span class="math"><em>z</em></span> to problem <span class="math"><em>Z</em></span> has size <span class="math"><em>n</em></span>, that the reduction from <span class="math"><em>Z</em></span> to <span class="math"><em>X</em></span> takes time <span class="math"><em>O</em>(<em>n</em><sup><em>c</em></sup>)</span>, and that the reduction from <span class="math"><em>X</em></span> to <span class="math"><em>Y</em></span> on an input of size <span class="math"><em>m</em></span> takes time <span class="math"><em>O</em>(<em>m</em><sup><em>d</em></sup>)</span>, where <span class="math"><em>c</em></span> and <span class="math"><em>d</em></span> are constants. The output of the reduction from <span class="math"><em>Z</em></span> to <span class="math"><em>X</em></span> cannot be longer than the time it took to produce it, and so this output, which is also the input <span class="math"><em>x</em></span> to the reduction from <span class="math"><em>X</em></span> to <span class="math"><em>Y</em></span>, has size <span class="math"><em>O</em>(<em>n</em><sup><em>c</em></sup>)</span>. Now we know that the size <span class="math"><em>m</em></span> of the input to the reduction from <span class="math"><em>X</em></span> to <span class="math"><em>Y</em></span> has size <span class="math"><em>m</em> = <em>O</em>(<em>n</em><sup><em>c</em></sup>)</span>, and so the time taken by the reduction from <span class="math"><em>X</em></span> to <span class="math"><em>Y</em></span> is <span class="math"><em>O</em>((<em>n</em><sup><em>c</em></sup>)<sup><em>d</em></sup>)</span>, which is <span class="math"><em>O</em>(<em>n</em><sup><em>c</em><em>d</em></sup>)</span>. Since <span class="math"><em>c</em></span> and <span class="math"><em>d</em></span> are constants, this second reduction takes time polynomial in <span class="math"><em>n</em></span>.</p>
<p>Furthermore, the time taken in the last stage, the polynomial-time algorithm for <span class="math"><em>Y</em></span>, is also polynomial in <span class="math"><em>n</em></span>. Suppose that the algorithm for <span class="math"><em>Y</em></span> on an input of size <span class="math"><em>p</em></span> takes time <span class="math"><em>O</em>(<em>p</em><sup><em>b</em></sup>)</span>, where <span class="math"><em>b</em></span> is a constant. As before, the output of a reduction cannot exceed the time taken to produce it, and so <span class="math"><em>p</em> = <em>O</em>(<em>n</em><sup><em>c</em><em>d</em></sup>)</span>, which means that the algorithm for <span class="math"><em>Y</em></span> takes time <span class="math"><em>O</em>((<em>n</em><sup><em>c</em><em>d</em></sup>)<sup><em>b</em></sup>)</span>, or <span class="math"><em>O</em>(<em>n</em><sup><em>b</em><em>c</em><em>d</em></sup>)</span>. Since <span class="math"><em>b</em></span>, <span class="math"><em>c</em></span>, and <span class="math"><em>d</em></span> are all constants, the algorithm for <span class="math"><em>Y</em></span> takes time polynomial in the original input size <span class="math"><em>n</em></span>. Altogether, the algorithm for <span class="math"><em>Z</em></span> takes time <span class="math"><em>O</em>(<em>n</em><sup><em>c</em></sup> + <em>n</em><sup><em>c</em><em>d</em></sup> + <em>n</em><sup><em>b</em><em>c</em><em>d</em></sup>)</span>, which is polynomial in <span class="math"><em>n</em></span>.</p>
<p>What have we just seen? We showed that if problem <span class="math"><em>X</em></span> is NP-hard and there is a polynomial-time reduction algorithm that transforms an input <span class="math"><em>x</em></span> to <span class="math"><em>X</em></span> into an input <span class="math"><em>y</em></span> to problem <span class="math"><em>Y</em></span>, then <span class="math"><em>Y</em></span> is NP-hard, too. Because <span class="math"><em>X</em></span> being NP-hard means that every problem in NP reduces to it in polynomial time, we picked any problem <span class="math"><em>Z</em></span> in NP that reduces to <span class="math"><em>X</em></span> in polynomial time and showed that it also reduces to <span class="math"><em>Y</em></span> in polynomial time.</p>
<p>So now all we have to do to show that a problem <span class="math"><em>Y</em></span> is NP-complete is</p>
<ul>
<li><p>show that it's in NP, which we can do by showing that there's a way to verify a certificate for <span class="math"><em>Y</em></span> in polynomial time, and</p></li>
<li><p>take some other problem <span class="math"><em>X</em></span> that we know to be NP-hard and give a polynomial-time reduction from <span class="math"><em>X</em></span> to <span class="math"><em>Y</em></span>.</p></li>
</ul>
<p>There is one more little detail that I've ignored so far: the Mother Problem. We need to start with some problem <span class="math"><em>M</em></span> (the Mother Problem) that <em>every</em> problem in NP reduces to in polynomial time. Then we can reduce <span class="math"><em>M</em></span> to <span class="math"><em>X</em></span> in polynomial time to show that <span class="math"><em>X</em></span> is NP-hard, reduce <span class="math"><em>X</em></span> to <span class="math"><em>Y</em></span> in polynomial time to show that <span class="math"><em>Y</em></span> is NP-hard, and so on. Bear in mind, too, that there's no limit on how many other problems we can reduce a single problem to, so that the family tree of NP-complete problems starts with the Mother Problem and then branches out.</p>
<h2 id="a-mother-problem">A Mother Problem</h2>
<p>Different books list different Mother Problems. That's fine, since once you reduce one Mother Problem to some other problem, that other problem could also serve as the Mother Problem. We'll use as our Mother Problem something called <strong>3-CNF satisfiability</strong>.</p>
<p>In 3-CNF satisfiability, we are given a formula with boolean variables. Each variable can take on the values 0 and 1, where you can think of 0 as False and 1 as True. The operators in the formula are the logical operators you know from Python, but we write them in capital letters: AND, OR, and NOT. We ask whether there is any way to assign boolean values (0 or 1) to the variables so that the formula evaluates to 1 (True). Note that we're not asking what that assignment of boolean values to the variables is, but just whether such an assignment exists.</p>
<p>The form of the formula is restricted: it has to be ANDs of <strong>clauses</strong>, where each clause is an OR of three terms, and each term is a <strong>literal</strong>: either a variable or the negation of a variable (such as <span class="math">NOT <em>x</em></span>). A boolean formula in this form is in <strong>3-conjunctive normal form</strong>, or <strong>3-CNF</strong>. For example, the boolean formula <span class="math">(<em>w</em> OR (NOT <em>w</em>) OR (NOT <em>x</em>)) AND (<em>y</em> OR <em>x</em> OR <em>z</em>) AND ((NOT <em>w</em>) OR (NOT <em>y</em>) OR (NOT <em>z</em>))</span> is in 3-CNF. Its first clause is <span class="math">(<em>w</em> OR (NOT <em>w</em>) OR (NOT <em>x</em>))</span>.</p>
<p>Deciding whether a boolean formula in 3-CNF has a satisfying assignment to its variables is NP-complete. A certificate is a proposed assignment of the values <span class="math">0</span> and <span class="math">1</span> to the variables. Checking a certificate is easy: just plug in the proposed values for the variables, and verify that the expression evaluates to <span class="math">1</span>. For 3-CNF satisfiability to truly be a Mother Problem, we'd have to show that every problem in NP reduces to it in polynomial time. You don't want to see this proof, at least not in this course.</p>
<p>Here's a frustrating aspect of 3-CNF satisfiability: although it's NP-complete, there is a polynomial-time algorithm to determine whether a 2-CNF formula is satisfiable. A 2-CNF formula is just like a 3-CNF formula except that it has two literals, not three, in each clause. A small change like that takes a problem from being as hard as any problem in NP to being easy!</p>
<h2 id="the-clique-problem">The clique problem</h2>
<p>Now we're going to see an interesting reduction, for problems in different domains: from 3-CNF satisfiability to a problem having to do with undirected graphs. A <strong>clique</strong> in an undirected graph <span class="math"><em>G</em></span> is a subset <span class="math"><em>S</em></span> of vertices such that the graph has an edge between every pair of vertices in <span class="math"><em>S</em></span>. The <strong>size of a clique</strong> is the number of vertices it contains.</p>
<p>As you might imagine, cliques play a role in social network theory. Modeling each individual as a vertex and relationships between individuals as undirected edges, a clique represents a group of individuals all of whom have relationships with each other. Cliques also have applications in bioinformatics, engineering, and chemistry.</p>
<p>The <strong>clique problem</strong> takes two inputs, a graph <span class="math"><em>G</em></span> and a positive integer <span class="math"><em>k</em></span>, and asks whether <span class="math"><em>G</em></span> has a clique of size <span class="math"><em>k</em></span>. (I could have phrased the problem as asking &quot;whether <span class="math"><em>G</em></span> has a clique of at least size <span class="math"><em>k</em></span>,&quot; but since a clique of size <span class="math"><em>k</em></span> contains within it cliques of all sizes less than <span class="math"><em>k</em></span>, the &quot;at least&quot; part is unnecessary.) For example, this graph has a clique of size <span class="math">4</span>, shown with heavily shaded vertices, and no other clique of size <span class="math">4</span> or greater:</p>
<div class="figure">
<img src="clique-4.png" /><p class="caption"></p>
</div>
<p>Verifying a certificate is easy. The certificate is the <span class="math"><em>k</em></span> vertices claimed to form a clique, and we just have to check that each of the <span class="math"><em>k</em></span> vertices has an edge to the other <span class="math"><em>k</em> - 1</span>. This check is easily performed in time polynomial in the size of the graph. Now we know that the clique problem is in NP.</p>
<p>How can a problem in satisfying boolean formulas possibly reduce to a graph problem? These two problems seem light years apart. One is a problem in boolean logic, and the other is a problem having to do with graphs. It's remarkable that we'll be able to reduce 3-CNF satisfiability to the clique problem, but we will do so.</p>
<p>We start with a boolean formula in 3-CNF. Suppose that the formula is <span class="math"><em>C</em><sub>1</sub> AND <em>C</em><sub>2</sub> AND <em>C</em><sub>3</sub> AND ⋯ AND <em>C</em><sub><em>k</em></sub></span>, where each <span class="math"><em>C</em><sub><em>r</em></sub></span> is one of <span class="math"><em>k</em></span> clauses. From this formula, we will construct a graph in polynomial time, and this graph will have a <span class="math"><em>k</em></span>-clique if and only if the 3-CNF formula is satisfiable. We need to see three things: the construction, an argument that the construction runs in time polynomial in the size of the 3-CNF formula, and a proof that the graph has a <span class="math"><em>k</em></span>-clique if and only if there is some way to assign to the variables of the 3-CNF formula so make it evaluate to <span class="math">1</span>.</p>
<p>To construct a graph from a 3-CNF formula, let's focus on the <span class="math"><em>r</em></span>th clause, <span class="math"><em>C</em><sub><em>r</em></sub></span>. It has three literals; let's call them <span class="math"><em>l</em><sub>1</sub><sup><em>r</em></sup></span>, <span class="math"><em>l</em><sub>2</sub><sup><em>r</em></sup></span>, and <span class="math"><em>l</em><sub>3</sub><sup><em>r</em></sup></span>, so that <span class="math"><em>C</em><sub><em>r</em></sub></span> is <span class="math"><em>l</em><sub>1</sub><sup><em>r</em></sup> AND <em>l</em><sub>2</sub><sup><em>r</em></sup> AND <em>l</em><sub>3</sub><sup><em>r</em></sup></span>. Each literal is either a variable or the negation of a variable. We create one vertex for each literal, so that for clause <span class="math"><em>C</em><sub><em>r</em></sub></span>, we create a triple of vertices, <span class="math"><em>v</em><sub>1</sub><sup><em>r</em></sup></span>, <span class="math"><em>v</em><sub>2</sub><sup><em>r</em></sup></span>, and <span class="math"><em>v</em><sub>3</sub><sup><em>r</em></sup></span>. We add an edge between vertices <span class="math"><em>v</em><sub><em>i</em></sub><sup><em>r</em></sup></span> and <span class="math"><em>v</em><sub><em>j</em></sub><sup><em>s</em></sup></span> if two conditions hold:</p>
<ul>
<li><p><span class="math"><em>v</em><sub><em>i</em></sub><sup><em>r</em></sup></span> and <span class="math"><em>v</em><sub><em>j</em></sub><sup><em>s</em></sup></span> are in different triples; that is, <span class="math"><em>r</em></span> and <span class="math"><em>s</em></span> are different clause numbers, and</p></li>
<li><p>their corresponding literals are not negations of each other.</p></li>
</ul>
<p>For example, here's a graph that corresponds to the 3-CNF formula <span class="math">(<em>x</em> OR (NOT <em>y</em>) OR (NOT <em>z</em>)) AND ((NOT <em>x</em>) OR <em>y</em> OR <em>z</em>) AND (<em>x</em> OR <em>y</em> OR <em>z</em>)</span>:</p>
<div class="figure">
<img src="clique-reduction.png" /><p class="caption"></p>
</div>
<p>It's easy enough to see that this reduction can be performed in polynomial time. If the 3-CNF formula has <span class="math"><em>k</em></span> clauses, then it has <span class="math">3<em>k</em></span> literals, and so the graph has <span class="math">3<em>k</em></span> vertices. At most, each vertex has an edge to all the other <span class="math">3<em>k</em> - 1</span> vertices, and so the number of edges is at most <span class="math">3<em>k</em>(3<em>k</em> - 1)</span>, which equals <span class="math">9<em>k</em><sup>2</sup> - 3<em>k</em></span>. Since the number <span class="math"><em>k</em></span> of clauses is smaller than the size of the input to the 3-CNF satisfiability problem, the graph constructed is polynomial in the size of the 3-CNF input, and it's easy to determine which edges go into the graph.</p>
<p>Finally, we need to show that the constructed graph has a <span class="math"><em>k</em></span>-clique if and only if the 3-CNF formula is satisfiable. We start by assuming that the formula is satisfiable, and we'll show that the graph has a <span class="math"><em>k</em></span>-clique. If there exists a satisfying assignment, each clause <span class="math"><em>C</em><sub><em>r</em></sub></span> contains at least one literal <span class="math"><em>l</em><sub><em>i</em></sub><sup><em>r</em></sup></span> that evaluates to <span class="math">1</span>, and each such literal corresponds to a vertex <span class="math"><em>v</em><sub><em>i</em></sub><sup><em>r</em></sup></span> in the graph. If we select one such literal from each of the <span class="math"><em>k</em></span> clauses, we get a corresponding set <span class="math"><em>S</em></span> of <span class="math"><em>k</em></span> vertices. I claim that <span class="math"><em>S</em></span> is a <span class="math"><em>k</em></span>-clique. Consider any two vertices in <span class="math"><em>S</em></span>. They correspond to literals in different clauses that evaluate to <span class="math">1</span> in the satisfying assignment. These literals cannot be negations of each other, because if they were, then one of them would evaluate to <span class="math">1</span> but the other would evaluate to <span class="math">0</span>. Since these literals are not negations of each other, we created an edge between the two vertices when we constructed the graph. Because we can pick any two vertices in <span class="math"><em>S</em></span> as this pair, we see that there are edges between all pairs of vertices in <span class="math"><em>S</em></span>. Hence, <span class="math"><em>S</em></span>, a set of <span class="math"><em>k</em></span> vertices, is a <span class="math"><em>k</em></span>-clique.</p>
<p>Now we have to show the other direction: if the graph has a <span class="math"><em>k</em></span>-clique <span class="math"><em>S</em></span>, then the 3-CNF formula is satisfiable. No edges in the graph connect vertices in the same triple, and so <span class="math"><em>S</em></span> contains exactly one vertex per triple. For each vertex <span class="math"><em>v</em><sub><em>r</em></sub><sup><em>i</em></sup></span> in <span class="math"><em>S</em></span>, assign <span class="math">1</span> to its corresponding literal <span class="math"><em>l</em><sub><em>r</em></sub><sup><em>i</em></sup></span> in the 3-CNF formula. We don't have to worry about assigning a <span class="math">1</span> to both a literal and its negation, since the <span class="math"><em>k</em></span>-clique cannot contain edges between vertices corresponding to a literal and its negation. Each clause is satisfied, and so the entire 3-CNF formula is satisfied. If any variables don't correspond to vertices in the clique, assign values to them arbitrarily; they won't affect the formula being satisfied.</p>
<p>In the above example, a satisfying assignment has <span class="math"><em>y</em> = 0</span> and <span class="math"><em>z</em> = 1</span>; it doesn't matter what we assign to <span class="math"><em>x</em></span>. A corresponding <span class="math">3</span>-clique consists of the heavily shaded vertices, which correspond to <span class="math">NOT <em>y</em></span> from clause <span class="math"><em>C</em><sub><em>i</em></sub></span> and <span class="math"><em>z</em></span> from clauses <span class="math"><em>C</em><sub>2</sub></span> and <span class="math"><em>C</em><sub>3</sub></span>.</p>
<p>Thus, we have shown that there exists a polynomial-time reduction from the NP-complete problem of 3-CNF satisfiability to the problem of finding a <span class="math"><em>k</em></span>-clique. If you were given a boolean formula in 3-CNF with <span class="math"><em>k</em></span> clauses, and you had to find a satisfying assignment for the formula, you could use the construction we just saw to convert the formula in polynomial time to an undirected graph, and determine whether the graph had a <span class="math"><em>k</em></span>-clique. If you could determine in polynomial time whether the graph had a <span class="math"><em>k</em></span>-clique, then you would have determined in polynomial time whether the 3-CNF formula had a satisfying assignment. Since 3-CNF satisfiability is NP-complete, so is determining whether a graph contains a <span class="math"><em>k</em></span>-clique. As a bonus, if you could determine not only whether the graph had a <span class="math"><em>k</em></span>-clique, but which vertices constituted the <span class="math"><em>k</em></span>-clique, then you could use this information to find the values to assign to the variables of the 3-CNF formula in a satisfying assignment.</p>
<h2 id="reductions-galore">Reductions galore</h2>
<p>I could give you dozens of reductions, each showing that some problem is NP-complete, but your eyes would quickly glaze over, if they haven't already. I wanted to show you the reduction from 3-CNF satisfiability to the clique problem because it shows how two problems, on the surface unrelated to each other, are actually the same problem—from the point of view of polynomial-time algorithms.</p>
<h2 id="perspective">Perspective</h2>
<p>I've painted quite a gloomy picture here, haven't I? Imagine a scenario in which you try to come up with a polynomial-time algorithm to solve a problem, and no matter how much you press, you just can't close the deal. After a while, you'd be thrilled just to find an <span class="math"><em>O</em>(<em>n</em><sup>5</sup>)</span>-time algorithm, even though you know that <span class="math"><em>n</em><sup>5</sup></span> grows awfully rapidly. Maybe this problem is close to one that you know is easily solved in polynomial time (such as 2-CNF satisfiability vs. 3-CNF, or Euler tour vs. hamiltonian cycle), and you find it incredibly frustrating that you can't adapt the polynomial-time algorithm for your problem. Eventually you suspect that maybe—just maybe—you've been banging your head against the wall to solve an NP-complete problem. And, lo and behold, you are able to reduce a known NP-complete problem to your problem, and now you know that it's NP-hard.</p>
<p>Is that the end of the story? There's no hope that you'll be able to solve the problem in any reasonable amount of time?</p>
<p>Not quite. When a problem is NP-complete, it means that <em>some</em> inputs are troublesome, but not necessarily that <em>all</em> inputs are bad. For example, finding a longest acyclic path in a directed graph is NP-complete, but if you know that the graph is acyclic, then you can find a longest acyclic path in not just polynomial time, but in <span class="math"><em>O</em>(<em>n</em> + <em>m</em>)</span> time (where the graph has <span class="math"><em>n</em></span> vertices and <span class="math"><em>m</em></span> edges).</p>
<p>The good news goes beyond such pathological special cases. From here on, let's focus on optimization problems whose decision variants are NP-complete, such as the traveling-salesman problem. Some fast methods give good, and often very good, results. The technique of <strong>branch and bound</strong> organizes a search for an optimal solution into a tree-like structure, and it cuts off hunks of the tree, thereby eliminating large portions of the search space, based on the simple idea that if it can determine that all the solutions emanating from one node of the search tree cannot be any better than the best solution found so far, then don't bother checking solutions within the space represented by that node or anything below it.</p>
<p>Another technique that often helps is <strong>neighborhood search</strong>, which takes one solution and applies local operations to try to improve the solution until no further improvement occurs.</p>
<p>Moreover, a host of <strong>approximation algorithms</strong> give results that are guaranteed to be within a certain factor of the optimal value. In many real-world situations, a nearly optimal solution is good enough. Harkening back to the discussion about the package-delivery company with brown trucks, they are happy to find nearly optimal routes for their trucks, even if the routes are not necessarily the best possible. Every dollar that they can save by planning efficient routes helps their bottom line.</p>
<p>Then again, if you're under the impression that NP-complete problems are the hardest in the world of algorithms, then you've got another thing coming. Theoretical computer scientists have defined a large hierarchy of complexity classes, based on how much time and other resources are necessary to solve a problem. Some problems take an amount of time that is provably exponential in the input size.</p>
<p>And it gets even worse. For some problems, no algorithm is possible. That is, there are problems for which it is provably impossible to create an algorithm that always gives a correct answer. We call such problems <strong>undecidable</strong>, and the best-known one is the <strong>halting problem</strong>, proven undecidable by the mathematician Alan Turing in 1937. In the halting problem, the input is a computer program A and the input <span class="math"><em>x</em></span> to A. The goal is to determine whether program A, running on input <span class="math"><em>x</em></span>, ever halts. That is, does A with input <span class="math"><em>x</em></span> run to completion?</p>
<p>Perhaps you're thinking that you could write a program let's call it program B—that reads in program A, reads in <span class="math"><em>x</em></span>, and simulates A running with input <span class="math"><em>x</em></span>. That's fine if A on input <span class="math"><em>x</em></span> actually does run to completion. What if it doesn't? How would program B know when to declare that A will never halt? Couldn't B check for A getting into some sort of infinite loop? The answer is that although you could write B to check for some cases in which A doesn't halt, it is provably impossible to write program B so that <em>it</em> always halts and tells you correctly whether A on input <span class="math"><em>x</em></span> halts.</p>
<p>Because it's not possible to write a program that determines whether another program running on a particular input even halts, it's also not possible to write a program that determines whether another program meets its specification. How can one program tell whether another program gives the right answer if it can't even tell whether the program halts? So much for perfect automated software testing!</p>
</body>
</html>
